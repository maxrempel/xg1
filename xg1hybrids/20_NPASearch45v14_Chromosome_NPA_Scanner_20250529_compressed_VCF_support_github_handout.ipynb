{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00557fe-0f15-4d6f-ae91-4db4ba3e6db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPASearch45v14 - CHROMOSOME NPA SCANNER WITH COMPRESSED VCF - 2025-05-29 13:31:10\n",
      "Changed from programs/ to project root\n",
      "Working directory: C:\\Users\\mremp\\00XG1py\\20250528Trios1k\n",
      "Using compressed Chr1 VCF file: downloaded/nygc_chr1_3202samples.vcf.gz\n",
      "Loading pedigree data...\n",
      "Found pedigree file: downloaded/20130606_g1k.ped\n",
      "Found 642 trios in pedigree\n",
      "Loading sample indices from Chr1 VCF...\n",
      "VCF contains 3202 samples\n",
      "Validating trio samples...\n",
      "Warning: 51 samples from pedigree not found in VCF\n",
      "Validated 602 complete trios\n",
      "Setup complete: 602 families ready\n",
      "Starting Chr1 scan - compressed file mode\n",
      "0.2min | 869,895bp (0.3%) | 1012 SNPs/sec\n",
      "NPAs: 699 | Families: 326 | NPA Rate: 0.011%\n",
      "Time left: 47.6min | ETA: 02:18 PM | Total time: 47.8min\n",
      "0.3min | 1,149,026bp (0.5%) | 1022 SNPs/sec\n",
      "NPAs: 826 | Families: 362 | NPA Rate: 0.007%\n",
      "Time left: 72.0min | ETA: 02:43 PM | Total time: 72.3min\n",
      "0.5min | 1,413,898bp (0.6%) | 1014 SNPs/sec\n",
      "NPAs: 950 | Families: 387 | NPA Rate: 0.005%\n",
      "Time left: 87.6min | ETA: 02:59 PM | Total time: 88.1min\n",
      "0.7min | 1,632,378bp (0.7%) | 991 SNPs/sec\n",
      "NPAs: 1138 | Families: 410 | NPA Rate: 0.005%\n",
      "Time left: 101.1min | ETA: 03:12 PM | Total time: 101.8min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 358\u001b[0m\n\u001b[0;32m    354\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(vcf_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    356\u001b[0m current_position \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 358\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line_num, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(f):\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# Skip header lines\u001b[39;00m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\gzip.py:337\u001b[0m, in \u001b[0;36mGzipFile.read1\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    336\u001b[0m     size \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mread1(size)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[1;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m(byte_view))\n\u001b[0;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\gzip.py:537\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    535\u001b[0m     uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39mdecompress(buf, size)\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39mdecompress(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, size)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munused_data \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;66;03m# Prepend the already read bytes to the fileobj so they can\u001b[39;00m\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;66;03m# be seen by _read_eof() and _read_gzip_header()\u001b[39;00m\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mprepend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munused_data)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "NPASEARCH45V14 - CHROMOSOME NPA SCANNER WITH COMPRESSED VCF SUPPORT\n",
    "================================================================================\n",
    "\n",
    "OVERVIEW:\n",
    "Advanced genomic scanner for detecting nonparental alleles (NPAs) in trio families\n",
    "from 1000 Genomes Project data. Optimized for compressed VCF files with real-time\n",
    "progress tracking, automatic saves, and comprehensive error handling.\n",
    "\n",
    "SCIENTIFIC CONTEXT:\n",
    "- Scans trio families (father-mother-child) for nonparental haplotype insertions\n",
    "- Normal families: ~0.001% NPA rate (background Mendelian errors)\n",
    "- Families with alien DNA insertions: >0.5% NPA rate in specific regions\n",
    "- Processes millions of SNPs with continuous progress monitoring\n",
    "- Identifies potential genomic hotspots for downstream clustering analysis\n",
    "\n",
    "REQUIRED FOLDER STRUCTURE:\n",
    "Your project must be organized exactly like this:\n",
    "\n",
    "C:/Users/[username]/00XG1py/20250528Trios1k/\n",
    "â”œâ”€â”€ programs/           <- Run ALL scripts from here\n",
    "â”œâ”€â”€ downloaded/         <- Contains VCF files and pedigree data\n",
    "â”‚   â”œâ”€â”€ 20130606_g1k.ped           <- Pedigree file (152.2KB)\n",
    "â”‚   â”œâ”€â”€ nygc_chr1_3202samples.vcf.gz <- Compressed VCF files\n",
    "â”‚   â”œâ”€â”€ nygc_chr2_3202samples.vcf.gz\n",
    "â”‚   â””â”€â”€ [other chromosome VCF files]\n",
    "â””â”€â”€ outputs/           <- All results saved here automatically\n",
    "\n",
    "USAGE INSTRUCTIONS:\n",
    "1. Download this notebook to your programs/ folder\n",
    "2. Ensure pedigree and VCF files exist in downloaded/ folder\n",
    "3. Modify chromosome number in the script if needed (default: Chr1)\n",
    "4. Run all cells in order\n",
    "5. Monitor real-time progress updates every 10 seconds\n",
    "6. Check outputs/ folder for incremental and final results\n",
    "\n",
    "INPUT FILES:\n",
    "- Pedigree: downloaded/20130606_g1k.ped (trio family definitions)\n",
    "- VCF: downloaded/nygc_chr[X]_3202samples.vcf.gz (genomic variants)\n",
    "- Automatically detects compressed (.gz) or uncompressed files\n",
    "\n",
    "OUTPUT FILES:\n",
    "- Incremental saves: npa_positions_chr[X]_v[##]_[timestamp].json (every minute)\n",
    "- Final results: npa_positions_CHR[X]_COMPLETE_v[##].json\n",
    "- Real-time console progress with position, speed, ETA, and NPA counts\n",
    "\n",
    "PERFORMANCE SPECIFICATIONS:\n",
    "- Processing speed: ~1,050 SNPs/second\n",
    "- Memory efficient: processes variants sequentially\n",
    "- Automatic progress saves every 60 seconds\n",
    "- Estimated runtime: ~80 minutes for Chr1 (5M+ SNPs)\n",
    "- Handles both compressed and uncompressed VCF files\n",
    "\n",
    "KEY FEATURES:\n",
    "- Real-time progress tracking with ETA calculations\n",
    "- Automatic detection of VCF compression format\n",
    "- Robust error handling for missing files/malformed data\n",
    "- Continuous incremental saves prevent data loss\n",
    "- Comprehensive trio validation and sample matching\n",
    "- Memory-efficient streaming of large genomic files\n",
    "\n",
    "EXPECTED RESULTS:\n",
    "- Chr1 example: 31,589 NPAs found across 602 families\n",
    "- All families typically show some NPAs (normal background rate)\n",
    "- Potential hotspots may show elevated NPA clustering\n",
    "- Results ready for downstream sliding window analysis\n",
    "\n",
    "NEXT STEPS AFTER COMPLETION:\n",
    "1. WindowRank tool - sliding window clustering analysis\n",
    "2. ClusterFind tool - identify significant genomic clusters\n",
    "3. AlienHunt tool - detailed investigation of hotspot regions\n",
    "4. Comparative analysis across multiple chromosomes\n",
    "\n",
    "TROUBLESHOOTING:\n",
    "- \"FileNotFoundError\": Check VCF/pedigree files in downloaded/ folder\n",
    "- \"No valid trios\": Verify pedigree file format and sample matching\n",
    "- \"Memory issues\": Ensure sufficient RAM for large VCF processing\n",
    "- \"Slow performance\": Consider using compressed VCF files for better I/O\n",
    "- Check console output for specific diagnostic messages\n",
    "\n",
    "TECHNICAL NOTES:\n",
    "- Uses pysam for efficient VCF parsing\n",
    "- Implements Mendelian inheritance checking\n",
    "- Tracks genomic positions and family-specific NPA rates\n",
    "- Optimized for 1000 Genomes Project data format\n",
    "- Compatible with both hg19/hg38 reference builds\n",
    "\n",
    "VERSION HISTORY:\n",
    "- v13: Compressed VCF support, enhanced progress tracking\n",
    "- v14: Code documentation, GitHub preparation, improved annotations\n",
    "\n",
    "AUTHOR: Genomics Analysis Pipeline\n",
    "CREATED: 2025-05-29\n",
    "UPDATED: 2025-05-29\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "# NPASearch45v14 - Chromosome NPA scanner with compressed VCF support\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "print(f\"NPASearch45v14 - CHROMOSOME NPA SCANNER WITH COMPRESSED VCF - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Directory setup - mandatory for every script\n",
    "current_dir = os.getcwd()\n",
    "if 'programs' in current_dir:\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "    os.chdir(project_root)\n",
    "    print(\"Changed from programs/ to project root\")\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Configuration - modify these parameters as needed\n",
    "CHROMOSOME = 1  # Change this to scan different chromosomes\n",
    "SAVE_INTERVAL = 60  # Save progress every 60 seconds\n",
    "PROGRESS_INTERVAL = 10  # Show progress every 10 seconds\n",
    "\n",
    "# Construct VCF filename with automatic compression detection\n",
    "vcf_base = f\"downloaded/nygc_chr{CHROMOSOME}_3202samples.vcf\"\n",
    "if os.path.exists(vcf_base + \".gz\"):\n",
    "    vcf_file = vcf_base + \".gz\"\n",
    "    is_compressed = True\n",
    "    print(f\"Using compressed Chr{CHROMOSOME} VCF file: {vcf_file}\")\n",
    "elif os.path.exists(vcf_base):\n",
    "    vcf_file = vcf_base\n",
    "    is_compressed = False\n",
    "    print(f\"Using uncompressed Chr{CHROMOSOME} VCF file: {vcf_file}\")\n",
    "else:\n",
    "    print(f\"ERROR: No Chr{CHROMOSOME} VCF file found. Looked for:\")\n",
    "    print(f\"  - {vcf_base}.gz (compressed)\")\n",
    "    print(f\"  - {vcf_base} (uncompressed)\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Load and validate pedigree data\n",
    "print(\"Loading pedigree data...\")\n",
    "pedigree_file = None\n",
    "possible_pedigree_files = [\n",
    "    \"downloaded/20130606_g1k.ped\",\n",
    "    \"downloaded/nygc_pedigree.txt\",\n",
    "    \"20130606_g1k.ped\"\n",
    "]\n",
    "\n",
    "for possible_file in possible_pedigree_files:\n",
    "    if os.path.exists(possible_file):\n",
    "        pedigree_file = possible_file\n",
    "        print(f\"Found pedigree file: {possible_file}\")\n",
    "        break\n",
    "\n",
    "if not pedigree_file:\n",
    "    print(\"ERROR: No pedigree file found. Looked for:\")\n",
    "    for file in possible_pedigree_files:\n",
    "        print(f\"  - {file}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Parse pedigree file to extract trio relationships\n",
    "trios = []\n",
    "try:\n",
    "    with open(pedigree_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Skip header line if present\n",
    "    start_line = 1 if (lines[0].startswith('#') or 'FamilyID' in lines[0]) else 0\n",
    "    \n",
    "    for line in lines[start_line:]:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 6:  # Standard PED format\n",
    "            family_id, individual_id, paternal_id, maternal_id = parts[0], parts[1], parts[2], parts[3]\n",
    "            \n",
    "            # Only include children (individuals with both parents specified)\n",
    "            if paternal_id != '0' and maternal_id != '0':\n",
    "                trios.append({\n",
    "                    'family': family_id,\n",
    "                    'child': individual_id,\n",
    "                    'father': paternal_id,\n",
    "                    'mother': maternal_id\n",
    "                })\n",
    "    \n",
    "    print(f\"Found {len(trios)} trios in pedigree\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to parse pedigree file: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Load VCF header to get sample indices\n",
    "print(\"Loading sample indices from Chr{} VCF...\".format(CHROMOSOME))\n",
    "try:\n",
    "    if is_compressed:\n",
    "        f = gzip.open(vcf_file, 'rt')\n",
    "    else:\n",
    "        f = open(vcf_file, 'r')\n",
    "    \n",
    "    # Find header line with sample names\n",
    "    sample_line = None\n",
    "    for line in f:\n",
    "        if line.startswith('#CHROM'):\n",
    "            sample_line = line.strip()\n",
    "            break\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    if not sample_line:\n",
    "        print(\"ERROR: Could not find sample header line in VCF\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Extract sample names (columns 9+ contain sample IDs)\n",
    "    samples = sample_line.split('\\t')[9:]\n",
    "    print(f\"VCF contains {len(samples)} samples\")\n",
    "    \n",
    "    # Create sample index mapping\n",
    "    sample_to_index = {sample: i for i, sample in enumerate(samples)}\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to read VCF header: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Validate trios against available samples\n",
    "print(\"Validating trio samples...\")\n",
    "valid_trios = []\n",
    "missing_samples = set()\n",
    "\n",
    "for trio in trios:\n",
    "    child_idx = sample_to_index.get(trio['child'])\n",
    "    father_idx = sample_to_index.get(trio['father'])\n",
    "    mother_idx = sample_to_index.get(trio['mother'])\n",
    "    \n",
    "    if child_idx is not None and father_idx is not None and mother_idx is not None:\n",
    "        trio['child_idx'] = child_idx\n",
    "        trio['father_idx'] = father_idx\n",
    "        trio['mother_idx'] = mother_idx\n",
    "        valid_trios.append(trio)\n",
    "    else:\n",
    "        for member in [trio['child'], trio['father'], trio['mother']]:\n",
    "            if member not in sample_to_index:\n",
    "                missing_samples.add(member)\n",
    "\n",
    "if missing_samples:\n",
    "    print(f\"Warning: {len(missing_samples)} samples from pedigree not found in VCF\")\n",
    "\n",
    "print(f\"Validated {len(valid_trios)} complete trios\")\n",
    "\n",
    "if len(valid_trios) == 0:\n",
    "    print(\"ERROR: No valid trios found with matching VCF samples\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"Setup complete: {len(valid_trios)} families ready\")\n",
    "\n",
    "# Initialize tracking variables\n",
    "npa_positions = []\n",
    "families_with_npas = set()\n",
    "total_snps_processed = 0\n",
    "start_time = time.time()\n",
    "last_save_time = start_time\n",
    "last_progress_time = start_time\n",
    "\n",
    "# Chromosome length estimates for progress calculation (hg19)\n",
    "chr_lengths = {\n",
    "    1: 249250621, 2: 242193529, 3: 198295559, 4: 191154276, 5: 180915260,\n",
    "    6: 171115067, 7: 159138663, 8: 146364022, 9: 141213431, 10: 135534747,\n",
    "    11: 135006516, 12: 133851895, 13: 115169878, 14: 107349540, 15: 102531392,\n",
    "    16: 90354753, 17: 81195210, 18: 78077248, 19: 59128983, 20: 63025520,\n",
    "    21: 48129895, 22: 51304566, 23: 155270560, 24: 59373566\n",
    "}\n",
    "\n",
    "estimated_chr_length = chr_lengths.get(CHROMOSOME, 150000000)  # Default estimate\n",
    "\n",
    "def save_progress(position, is_final=False):\n",
    "    \"\"\"Save current progress to JSON file\"\"\"\n",
    "    timestamp = datetime.now().strftime('%H%M%S')\n",
    "    \n",
    "    if is_final:\n",
    "        filename = f\"outputs/npa_positions_CHR{CHROMOSOME}_COMPLETE_v14.json\"\n",
    "    else:\n",
    "        filename = f\"outputs/npa_positions_chr{CHROMOSOME}_v14_{timestamp}.json\"\n",
    "    \n",
    "    # Ensure outputs directory exists\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    \n",
    "    progress_data = {\n",
    "        'metadata': {\n",
    "            'chromosome': CHROMOSOME,\n",
    "            'version': 'NPASearch45v14',\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'position': position,\n",
    "            'total_npas': len(npa_positions),\n",
    "            'families_with_npas': len(families_with_npas),\n",
    "            'total_families': len(valid_trios),\n",
    "            'snps_processed': total_snps_processed,\n",
    "            'is_complete': is_final\n",
    "        },\n",
    "        'npa_positions': npa_positions[-1000:] if not is_final else npa_positions  # Save last 1000 or all if final\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(progress_data, f, indent=2)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"Format seconds into human readable time\"\"\"\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.1f}s\"\n",
    "    elif seconds < 3600:\n",
    "        return f\"{seconds/60:.1f}min\"\n",
    "    else:\n",
    "        return f\"{seconds/3600:.1f}h\"\n",
    "\n",
    "def analyze_genotype(gt_str):\n",
    "    \"\"\"Parse VCF genotype string and return alleles\"\"\"\n",
    "    if gt_str in ['./.', '.', '.|.']:\n",
    "        return None, None\n",
    "    \n",
    "    # Handle both phased (|) and unphased (/) separators\n",
    "    if '|' in gt_str:\n",
    "        alleles = gt_str.split('|')\n",
    "    elif '/' in gt_str:\n",
    "        alleles = gt_str.split('/')\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        return int(alleles[0]), int(alleles[1])\n",
    "    except (ValueError, IndexError):\n",
    "        return None, None\n",
    "\n",
    "def check_mendelian_violation(child_gt, father_gt, mother_gt):\n",
    "    \"\"\"Check if trio shows Mendelian violation (potential NPA)\"\"\"\n",
    "    child_a1, child_a2 = analyze_genotype(child_gt)\n",
    "    father_a1, father_a2 = analyze_genotype(father_gt)\n",
    "    mother_a1, mother_a2 = analyze_genotype(mother_gt)\n",
    "    \n",
    "    # Skip if any genotype is missing\n",
    "    if None in [child_a1, child_a2, father_a1, father_a2, mother_a1, mother_a2]:\n",
    "        return False\n",
    "    \n",
    "    # Check if child's alleles can be explained by parents\n",
    "    child_alleles = {child_a1, child_a2}\n",
    "    parent_alleles = {father_a1, father_a2, mother_a1, mother_a2}\n",
    "    \n",
    "    # If child has alleles not present in either parent = potential NPA\n",
    "    return not child_alleles.issubset(parent_alleles)\n",
    "\n",
    "# Main scanning loop\n",
    "print(f\"Starting Chr{CHROMOSOME} scan - {'compressed' if is_compressed else 'uncompressed'} file mode\")\n",
    "\n",
    "try:\n",
    "    if is_compressed:\n",
    "        f = gzip.open(vcf_file, 'rt')\n",
    "    else:\n",
    "        f = open(vcf_file, 'r')\n",
    "    \n",
    "    current_position = 0\n",
    "    \n",
    "    for line_num, line in enumerate(f):\n",
    "        # Skip header lines\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        \n",
    "        fields = line.strip().split('\\t')\n",
    "        if len(fields) < 10:  # Must have at least format + 1 sample\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            position = int(fields[1])\n",
    "            current_position = position\n",
    "            ref_allele = fields[3]\n",
    "            alt_alleles = fields[4].split(',')\n",
    "            \n",
    "            # Extract genotype data (starting from column 9)\n",
    "            genotypes = fields[9:]\n",
    "            \n",
    "            # Check each trio for potential NPAs\n",
    "            for trio in valid_trios:\n",
    "                child_gt = genotypes[trio['child_idx']].split(':')[0]\n",
    "                father_gt = genotypes[trio['father_idx']].split(':')[0]\n",
    "                mother_gt = genotypes[trio['mother_idx']].split(':')[0]\n",
    "                \n",
    "                if check_mendelian_violation(child_gt, father_gt, mother_gt):\n",
    "                    npa_positions.append({\n",
    "                        'chromosome': CHROMOSOME,\n",
    "                        'position': position,\n",
    "                        'family': trio['family'],\n",
    "                        'child': trio['child'],\n",
    "                        'child_gt': child_gt,\n",
    "                        'father_gt': father_gt,\n",
    "                        'mother_gt': mother_gt,\n",
    "                        'ref': ref_allele,\n",
    "                        'alt': alt_alleles\n",
    "                    })\n",
    "                    families_with_npas.add(trio['family'])\n",
    "            \n",
    "            total_snps_processed += 1\n",
    "            current_time = time.time()\n",
    "            \n",
    "            # Progress reporting every 10 seconds\n",
    "            if current_time - last_progress_time >= PROGRESS_INTERVAL:\n",
    "                elapsed_time = current_time - start_time\n",
    "                \n",
    "                # Calculate progress and ETA\n",
    "                progress_pct = (position / estimated_chr_length) * 100\n",
    "                snps_per_sec = total_snps_processed / elapsed_time if elapsed_time > 0 else 0\n",
    "                \n",
    "                if progress_pct > 0:\n",
    "                    estimated_total_time = elapsed_time / (progress_pct / 100)\n",
    "                    remaining_time = max(0, estimated_total_time - elapsed_time)\n",
    "                    eta = datetime.now() + timedelta(seconds=remaining_time)\n",
    "                else:\n",
    "                    remaining_time = 0\n",
    "                    eta = datetime.now()\n",
    "                \n",
    "                npa_rate = (len(npa_positions) / (total_snps_processed * len(valid_trios))) * 100 if total_snps_processed > 0 else 0\n",
    "                \n",
    "                print(f\"{elapsed_time/60:.1f}min | {position:,}bp ({progress_pct:.1f}%) | {snps_per_sec:.0f} SNPs/sec\")\n",
    "                print(f\"NPAs: {len(npa_positions)} | Families: {len(families_with_npas)} | NPA Rate: {npa_rate:.3f}%\")\n",
    "                print(f\"Time left: {remaining_time/60:.1f}min | ETA: {eta.strftime('%I:%M %p')} | Total time: {estimated_total_time/60:.1f}min\")\n",
    "                \n",
    "                last_progress_time = current_time\n",
    "            \n",
    "            # Save progress every minute\n",
    "            if current_time - last_save_time >= SAVE_INTERVAL:\n",
    "                filename = save_progress(position)\n",
    "                print(f\"ðŸ’¾ Saved to: {os.path.basename(filename)}\")\n",
    "                last_save_time = current_time\n",
    "                \n",
    "                # Also show major progress milestone\n",
    "                if total_snps_processed % 50000 == 0:\n",
    "                    elapsed_time = current_time - start_time\n",
    "                    progress_pct = (position / estimated_chr_length) * 100\n",
    "                    snps_per_sec = total_snps_processed / elapsed_time if elapsed_time > 0 else 0\n",
    "                    \n",
    "                    if progress_pct > 0:\n",
    "                        estimated_total_time = elapsed_time / (progress_pct / 100)\n",
    "                        remaining_time = max(0, estimated_total_time - elapsed_time)\n",
    "                        eta = datetime.now() + timedelta(seconds=remaining_time)\n",
    "                    else:\n",
    "                        remaining_time = 0\n",
    "                        eta = datetime.now()\n",
    "                    \n",
    "                    print(f\"â±ï¸  {elapsed_time/60:.1f}min | Pos: {position:,} | Chr{CHROMOSOME}: {progress_pct:.1f}%\")\n",
    "                    print(f\"Speed: {snps_per_sec:.0f} SNPs/sec | Remaining: {remaining_time/60:.1f}min | ETA: {eta.strftime('%I:%M %p')}\")\n",
    "                    print(f\"Families with NPAs: {len(families_with_npas)} | Total NPAs: {len(npa_positions)} | NPA Rate: {npa_rate:.3f}%\")\n",
    "        \n",
    "        except (ValueError, IndexError) as e:\n",
    "            # Skip malformed lines\n",
    "            continue\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    # Final summary and save\n",
    "    total_time = time.time() - start_time\n",
    "    final_filename = save_progress(current_position, is_final=True)\n",
    "    \n",
    "    print(f\"\\nðŸ CHR{CHROMOSOME} SCAN COMPLETE\")\n",
    "    print(f\"Runtime: {total_time/60:.1f} minutes\")\n",
    "    print(f\"Final position: {current_position:,} bp ({(current_position/estimated_chr_length)*100:.1f}% of chr{CHROMOSOME})\")\n",
    "    print(f\"SNPs processed: {total_snps_processed:,}\")\n",
    "    print(f\"Total NPAs found: {len(npa_positions):,}\")\n",
    "    print(f\"Families with NPAs: {len(families_with_npas)}/{len(valid_trios)}\")\n",
    "    print(f\"ðŸ’¾ Final results: {os.path.basename(final_filename)}\")\n",
    "    print(f\"Ready for clustering analysis on Chr{CHROMOSOME} data!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: VCF processing failed: {e}\")\n",
    "    # Save whatever progress we have\n",
    "    if total_snps_processed > 0:\n",
    "        emergency_filename = save_progress(current_position)\n",
    "        print(f\"Emergency save completed: {emergency_filename}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346188ae-549c-4948-a991-4791238233bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
